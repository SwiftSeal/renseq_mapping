import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from Bio import SeqIO

experiment_name = config["experiment_name"]

def get_reference():
    return config["reference"]["fasta"]

def get_reads(wildcards):
    R1 = config[wildcards.source][wildcards.phenotype]["R1"]
    R2 = config[wildcards.source][wildcards.phenotype]["R2"]
    return R1, R2

def get_thresholds(wildcards):
    susceptible_min = config["allele_frequency"][wildcards.source]["susceptible"]["min"]
    susceptible_max = config["allele_frequency"][wildcards.source]["susceptible"]["max"]
    resistant_min = config["allele_frequency"][wildcards.source]["resistant"]["min"]
    resistant_max = config["allele_frequency"][wildcards.source]["resistant"]["max"]

    return susceptible_min, susceptible_max, resistant_min, resistant_max

if config["mode"] == "mapping":
    include: "rules/mapping.smk"
    rule all:
        input:
            expand("results/{experiment}/filtered/{source}.vcf", source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/plots/{source}.png", source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/result.tsv", experiment = experiment_name),
            expand("results/{experiment}/blast.txt", experiment = experiment_name)
elif config["mode"] == "standard":
    rule all:
        input:
            expand("results/{experiment}/filtered/{source}.vcf", source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/plots/{source}.png", source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/result.tsv", experiment = experiment_name)
elif config["mode"] == "report":
    rule all:
        input:
            expand("results/{experiment}/filtered/{source}.vcf", source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/plots/{source}.png". source = ["parent", "bulk"], experiment = experiment_name),
            expand("results/{experiment}/result.tsv", experiment = experiment_name),
            expand("results/{experiment}/result_repulsion.tsv", experiment = experiment_name),
            expand("results/{experiment}/result_null.tsv", experiment = experiment_name)
            expand("results/{experiment}/blast_plot.png", experiment = experiment_name),
            expand("results/{experiment}/report.txt", experiment = experiment_name)
else:
    raise ValueError("Invalid mode specified in config file")

rule bowtie2_index:
    input:
        fasta = get_reference()
    output:
        expand("results/{experiment}/reference/reference.{i}.bt2", i = [1, 2, 3, 4, "rev.1", "rev.2"], experiment = experiment_name)
    params:
        index_directory = expand("results/{experiment}/reference/reference", experiment = experiment_name)
    conda:
        "envs/bowtie2.yaml"
    threads: 1
    resources:
        mem_mb = 8000,
        partition = "short"
    shell:
        """
        bowtie2-build {input.fasta} {params.index_directory}
        """

rule fastp:
    input:
        R1 = lambda wildcards: get_reads(wildcards)[0],
        R2 = lambda wildcards: get_reads(wildcards)[1]
    output:
        R1 = temp("results/{experiment}/fastp/{source}.{phenotype}.R1.fastq.gz"),
        R2 = temp("results/{experiment}/fastp/{source}.{phenotype}.R2.fastq.gz")

    conda:
        "envs/bowtie2.yaml"
    threads:
        4
    resources:
        mem_mb = 4000,
        partition = "short"
    shell:
        """
        fastp -i {input.R1} -I {input.R2} -o {output.R1} -O {output.R2} -h "results/{wildcards.experiment}/fastp/{wildcards.source}.{wildcards.phenotype}.html" -j "results/{wildcards.experiment}/fastp/{wildcards.source}.{wildcards.phenotype}.json"
        """

rule count_reads:
    input:
        R1 = "results/{experiment}/fastp/{source}.{phenotype}.R1.fastq.gz",
        R2 = "results/{experiment}/fastp/{source}.{phenotype}.R2.fastq.gz"
    output:
        counts = "results/{experiment}/read_counts/{source}.{phenotype}.readcounts.txt"
    resources:
        mem_mb = 4000,
        partition = "short"
    shell:
        """
        R1_count=$(echo $(zcat {input.R1} | wc -l)/4 | bc)
        R2_count=$(echo $(scat {input.R2} | wc -l)/4 | bc)
        printf "{source}\t{phenotype}" > {output}
        printf "R1\t$R1_count" >> {output}
        printf "R2\t$R2_count" >> {output}
        """

rule bowtie2_align:
    input:
        R1 = "results/{experiment}/fastp/{source}.{phenotype}.R1.fastq.gz",
        R2 = "results/{experiment}/fastp/{source}.{phenotype}.R2.fastq.gz",
        index = "results/{experiment}/reference/reference.1.bt2"
    output:
        bam = temp("results/{experiment}/bowtie2_align/{source}.{phenotype}.bam")
    params:
        bowtie2_args = config["bowtie2_args"],
        index_directory = "results/{experiment}/reference/reference"
    conda:
        "envs/bowtie2.yaml"
    threads:
        16
    resources:
        mem_mb = 4000,
        partition = "short"
    shell:
        """
        bowtie2 -p {threads} {params.bowtie2_args} -x {params.index_directory} -1 {input.R1} -2 {input.R2} | samtools view -bS - > {output}
        """

rule sort_bam:
    input:
        "results/{experiment}/bowtie2_align/{source}.{phenotype}.bam"
    output:
        temp("results/{experiment}/bowtie2_align/{source}.{phenotype}.sorted.bam")
    conda:
        "envs/bowtie2.yaml"
    shell:
        """
        samtools sort -o {output} {input}
        """

rule mpileup:
    input:
        resistant = "results/{experiment}/bowtie2_align/{source}.resistant.sorted.bam",
        susceptible = "results/{experiment}/bowtie2_align/{source}.susceptible.sorted.bam",
        reference = get_reference()
    output:
        temp("results/{experiment}/mpileup/{source}.mpileup")
    conda:
        "envs/bowtie2.yaml"
    shell:
        """
        # mpileup builds an index at location of reference, so copy to tmpdir
        cp {input.reference} $TMPDIR/reference.fa
        samtools mpileup -f $TMPDIR/reference.fa {input.resistant} {input.susceptible} > {output}
        """

rule varscan:
    input:
        "results/{experiment}/mpileup/{source}.mpileup"
    output:
        "results/{experiment}/varscan/{source}.vcf"
    conda:
        "envs/bowtie2.yaml"
    shell:
        """
        varscan mpileup2snp {input} --output-vcf 1 --strand-filter 0 > {output}
        """

rule plot_variants_frequency:
    input:
        "results/{experiment}/varscan/{source}.vcf"
    output:
        report("results/{experiment}/plots/{source}.png")
    run:
        with open(input[0]) as infile:
            source = []
            frequency = []
            for line in infile:
                # ignore header lines
                if line.startswith("#"):
                    continue
                
                fields = line.split("\t")
                keys = fields[8].split(":")
                resistant = fields[9].split(":")
                susceptible = fields[10].split(":")
                
                # error and warn user if operating on wrong field
                if keys[6] != "FREQ":
                    raise ValueError("Expected FREQ field at position 7, got {} instead".format(keys[6]))

                if len(resistant) != len(keys) or len(susceptible) != len(keys):
                    continue
                
                # convert freq to float
                resistant_freq = float(resistant[6].rstrip("%"))
                susceptible_freq = float(susceptible[6].rstrip("%"))

                # add to dataframe
                source.append("resistant")
                frequency.append(resistant_freq)
                source.append("susceptible")
                frequency.append(susceptible_freq)

            # create dataframe
            df = pd.DataFrame({"source": source, "frequency": frequency})
            
            # plot
            sns.displot(df, x = "frequency", hue = "source", kind = "kde")
            plt.savefig(output[0])
    
rule filter_variants:
    input:
        "results/{experiment}/varscan/{source}.vcf"
    output:
        report("results/{experiment}/filtered/{source}.vcf")
    params:
        susceptible_min = lambda wildcards: get_thresholds(wildcards)[0],
        susceptible_max = lambda wildcards: get_thresholds(wildcards)[1],
        resistant_min = lambda wildcards: get_thresholds(wildcards)[2],
        resistant_max = lambda wildcards: get_thresholds(wildcards)[3]
    run:
        with open(input[0]) as infile, open(output[0], "w") as outfile:
            for line in infile:
                # ignore header lines
                if line.startswith("#"):
                    outfile.write(line)
                else:
                    fields = line.split("\t")
                    keys = fields[8].split(":")
                    resistant = fields[9].split(":")
                    susceptible = fields[10].split(":")

                    # error and warn user if operating on wrong field
                    if keys[6] != "FREQ":
                        raise ValueError("Expected FREQ field at position 7, got {} instead".format(keys[6]))

                    # ignore lines where resistant or susceptible is busted
                    if len(resistant) != len(keys) or len(susceptible) != len(keys):
                        continue
                    
                    # convert freq to float
                    resistant_freq = float(resistant[6].rstrip("%"))
                    susceptible_freq = float(susceptible[6].rstrip("%"))

                    # write out if freq is within bounds
                    if params.susceptible_min <= susceptible_freq <= params.susceptible_max and params.resistant_min <= resistant_freq <= params.resistant_max:
                        outfile.write(line)
                    elif 100 - params.susceptible_max <= susceptible_freq <= 100 - params.susceptible_min and 100 - params.resistant_max <= resistant_freq <= 100 - params.resistant_min:
                        outfile.write(line)
                    
rule merge_variants:
    input:
        expand("results/{experiment}/filtered/{source}.vcf", source = ["parent", "bulk"], experiment = experiment_name)
    output:
        report("results/{experiment}/result.tsv")
    run:
        parent_df = pd.read_csv(input[0], sep = "\t", comment = "#", header = None)
        parent_df = parent_df[[0, 1]]
        parent_df.columns = ["chromosome", "position"]

        bulk_df = pd.read_csv(input[1], sep = "\t", comment = "#", header = None)
        bulk_df = bulk_df[[0, 1]]
        bulk_df.columns = ["chromosome", "position"]

        # add source column
        parent_df["source"] = "parent"
        bulk_df["source"] = "bulk"

        intersect = pd.merge(parent_df, bulk_df, how = "inner", on = ["chromosome", "position"])

        # write out
        intersect.to_csv(output[0], sep = "\t", index = False)
